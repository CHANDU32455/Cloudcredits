# ğŸ¡ California House Price Prediction

This project is developed as part of the **CloudCredits ML & AI Internship**. It predicts median house prices in California using the California Housing dataset from `sklearn.datasets`.

We use **Linear Regression with Polynomial Features** to model the data. The application includes a **Streamlit-based UI** where users can input house-related features and receive real-time price predictions, along with downloadable PDF reports.

---

## ğŸ¯ Features

- âœ”ï¸ Linear Regression with Polynomial Feature Expansion
- âœ”ï¸ Log-transformation of target variable for stability
- âœ”ï¸ `StandardScaler` normalization
- âœ”ï¸ Diagnostic plots: Actual vs Predicted, Residual Histogram
- âœ”ï¸ Streamlit UI for prediction and report generation
- âœ”ï¸ PDF export of predictions
- âœ”ï¸ Logging and modular pipeline design

---

## ğŸ“‚ Project Structure

```bash
HousePricePrediction
â”œâ”€â”€ train_model.py # Trains and saves the model
â”œâ”€â”€ ui_app.py # Streamlit app for predictions
â”œâ”€â”€ model/
â”‚ â”œâ”€â”€ house_model.pkl
â”‚ â”œâ”€â”€ scaler.pkl
â”‚ â”œâ”€â”€ poly_transformer.pkl
â”‚ â””â”€â”€ predictions/ # Saved PDF reports
â”œâ”€â”€ reports/
â”‚ â”œâ”€â”€ actual_vs_pred.png
â”‚ â””â”€â”€ residual_hist.png
â”œâ”€â”€ UI_output.png # Screenshot of UI
â””â”€â”€ README.md
```

---

## ğŸ–¥ï¸ Output

### Streamlit UI Example:

![Streamlit Web Interface](./UI_output.png)

---

## ğŸ”§ How to use

1. **Train the model** (if not already trained):
   ```bash
   python train_model.py
   ```

    Launch the prediction UI:

    ```bash

    streamlit run ui_app.py
    ```

2.  **Interact with the app**

       -  Fill in feature inputs like median income, house age, location, etc.

       -  View the predicted price.

       -  Saved a PDF report.

       -  View past predictions from the sidebar.

3. **Model Improvements and Results**

We applied several improvements to enhance the efficiency and accuracy of the model:

  - Split raw data before preprocessing.

  - Polynomial features are created and scaled.

  - Target is log-transformed during training (log1p).

  - During evaluation, predictions are inverse-transformed using expm1.

  - The PolynomialFeatures transformer is saved alongside the model and scaler.

  - Diagnostic plots illustrate:

      - Actual vs Predicted values

      - Residual distribution

  - Logging provides clear progress tracking and error reporting.

## ğŸ“Š Results:

  - Mean Squared Error (MSE): 0.4536 â€” significantly improved from previous 0.5559.

  - RÂ² Score: 0.6539 â€” improved from about 0.5758, now explaining ~65% of the variance.

I believe these results are decent for a basic linear regression approach with polynomial expansion, especially considering the simplicity of the model.

## ğŸ“Œ Conclusion

This project demonstrates how classic machine learning methodsâ€”when combined with proper preprocessing, transformations, and a clean interfaceâ€”can be used effectively for real-world prediction tasks.

While the model performs fairly well, future improvements can include:

  - Trying other regressors like Ridge, Lasso, or Gradient Boosting

  - Feature engineering and selection

  - Cross-validation and hyperparameter tuning